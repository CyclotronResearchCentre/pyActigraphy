{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Multi-fractal)Detrended fluctuation analysis\n",
    "\n",
    "Human activity exhibits a temporal organization characterised by scale-invariant (fractal) patterns over time scales ranging from minutes to 24 hours. The (MF)DFA method allows the quantification of this scale-invariance.\n",
    "\n",
    "The (MF)DFA methods have been originally described in:\n",
    "\n",
    "* Peng, C.-K., Buldyrev, S. V., Havlin, S., Simons, M., Stanley, H. E., & Goldberger, A. L. (1994). Mosaic organization of DNA nucleotides. Physical Review E, 49(2), 1685–1689. https://doi.org/10.1103/PhysRevE.49.1685\n",
    "* Kantelhardt, J. W., Zschiegner, S. A., Koscielny-Bunde, E., Havlin, S., Bunde, A., & Stanley, H. E. (2002). Multifractal detrended fluctuation analysis of nonstationary time series. Physica A: Statistical Mechanics and Its Applications, 316(1–4), 87–114. https://doi.org/10.1016/S0378-4371(02)01383-3\n",
    "\n",
    "Aging and Alzheimer’s disease, both marked by an alteration of the suprachiasmatic nucleus (SCN), the circadian pacemaker, have been associated with a degradation of this scale-invariant organization. More informations in:\n",
    "\n",
    "* Hu, K., Van Someren, E. J. W., Shea, S. A., & Scheer, F. A. J. L. (2009). Reduction of scale invariance of activity fluctuations with aging and Alzheimer’s disease: Involvement of the circadian pacemaker. Proceedings of the National Academy of Sciences, 106(8), 2490–2494. https://doi.org/10.1073/pnas.0806087106\n",
    "* Li, P., Yu, L., Lim, A. S. P., Buchman, A. S., Scheer, F. A. J. L., Shea, S. A., … Hu, K. (2018). Fractal regulation and incident Alzheimer’s disease in elderly individuals. Alzheimer’s & Dementia, 14(9), 1114–1125. https://doi.org/10.1016/j.jalz.2018.03.010\n",
    "* Li, P., Yu, L., Yang, J., Lo, M. T., Hu, C., Buchman, A. S., … Hu, K. (2019). Interaction between the progression of Alzheimer’s disease and fractal degradation. Neurobiology of Aging, 83, 21–30. https://doi.org/10.1016/j.neurobiolaging.2019.08.023\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DFA steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a nutshell, the DFA method consists in:\n",
    "\n",
    "1. removing the global mean and integrating the time series of a signal, that is:\n",
    "$$ X_{t} = \\sum_i^N(x_i - \\bar{x}) $$\n",
    "where $\\bar{x}$ denotes the mean value of the time series $\\{x_i\\}_{i\\in[1:N]}$\n",
    "2. dividing the integrated signal into nonoverlapping windows of the same chosen size n;\n",
    "3. detrending the integrated signal in each window using polynomial functions to obtain residuals, that is:\n",
    "$$ \\widehat{X_t} = X_{t} - Y_{t}$$ \n",
    "where $Y_t$ denotes the trend obtained by polynomial fit and $\\widehat{X_t}$ the integrated time series after detrending;\n",
    "4. calculating the root mean square of residuals in all windows as detrended fluctuation amplitude F(n), that is:\n",
    "$$ F_n = \\sqrt{\\frac{1}{N} \\sum_{t=1}^N \\widehat{X_t}^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import your favourite packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyActigraphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "fpath = os.path.join(os.path.dirname(pyActigraphy.__file__),'tests/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The DFA methods are part of the Fractal module:\n",
    "from pyActigraphy.analysis import Fractal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Fractal.dfa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read test file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pyActigraphy.io.read_raw_awd(fpath+'example_01.AWD', start_time='1918-01-24 08:00:00', period='9 days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.duration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to illustrate how the method works, let's review its different steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal detrending and integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = Fractal.profile(raw.data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create figure with secondary y-axis\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=raw.data.index.astype(str),y=raw.data.values, name='Data'),\n",
    "    secondary_y=False,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=raw.data.index.astype(str),y=profile, name='Profile'),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "# Add figure title\n",
    "fig.update_layout(\n",
    "    title_text=\"Detrended and integrated data profile\"\n",
    ")\n",
    "\n",
    "# Set x-axis title\n",
    "fig.update_xaxes(title_text=\"Date time\")\n",
    "# Set y-axes titles\n",
    "fig.update_yaxes(title_text=\"Activity counts\", secondary_y=False)\n",
    "#fig.update_yaxes(title_text=\"<b>secondary</b> yaxis title\", secondary_y=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By definition, the profile values at the beginning and the end of the recording is zero, as shown on the plot.\n",
    "\n",
    "As a side remark, it is interesting to note how the total daily activity fluctuates; the mean activity of the first three days is significantly lower than the activity of the remaining days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal segmentation into non-overlapping windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step of the DFA method consists to divide the signal into consecutive non-overlapping segments of equal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Fractal.segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of segmentation with a window size of 1000 elements.\n",
    "n = 1000\n",
    "segments = Fractal.segmentation(profile, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the profile has been segmented into 12 windows of size 1000. The remaining points are discarded. In order to avoid any bias from these discarded points, the DFA method, implemented in *pyActigraphy* averages over the results obtained over segments made from the start (foward) and from the end (backward) of the recording."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local and global q-th order fluctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Fractal.local_msq_residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, the local fluctuations (i.e mean squared residuals of a least-square fit using a polynomial of order 1) are computed for each segment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fluctuations = [Fractal.local_msq_residuals(segment,deg=1) for segment in segments]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the local fluctuations are averaged over all segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(Fractal.q_th_order_mean_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DFA method corresponds to $q=2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fractal.q_th_order_mean_square(local_fluctuations,q=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value correspond the global fluctuation observed at a time scale of $n=1000$. The previous steps are repeated for various values of $n$ in order to estimate the function $F_q(n)$. \n",
    "\n",
    "In case of scale-invariance, this function should scale as: $$F_q(n) \\propto n^{h(q)}$$ with $h(q)$ the generalized scaling (or Hurst) exponent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DFA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the various functions illustrated above, the *pyActigraphy* implements a global function that performs all the necessary steps to carry out a DFA analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Fractal.dfa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first construct an array of time scales (in minutes, as mentioned in the \"help\" documentation), at which we would like to evaluate the fluctuations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_array = np.geomspace(10, 1440, num=50, endpoint=True, dtype=int) # Numbers spaced evenly on a log scale, ranging from an ultradian time scale (10 min.) to a circadian one (1440 min, i.e. 24h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we calculate the associated fluctuations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_n = Fractal.dfa(raw.data,n_array,deg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[\n",
    "    go.Scatter(x=n_array,y=np.log(F_n), name='Data fluctuation',mode='markers+lines')])\n",
    "fig.update_layout(\n",
    "    height=800, width=800,\n",
    "    xaxis=dict(title='Time (min.)',type='log'),\n",
    "    yaxis=dict(title='log(F(n))')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since human locomoter activity is characterized by a scale-invariant pattern, the log-log plot of $F_q(n)$ vs $n$ shows a linear behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the generalized Hurst exponent can be extracted using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fractal.generalized_hurst_exponent(F_n, n_array, log=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generalized Hurst exponent for this recording is:\n",
    "$$ h(q=2) = 0.996 \\pm 0.005$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multifractal DFA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Briefly, the MFDFA method extends the DFA method by evaluating the local fluctuations at various q-orders (instead of just q=2 for DFA). This results in a series of series of fluctuations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In *pyActigraphy*, similarly to the DFA, a MFDFA can be performed with a single function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Fractal.mfdfa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define an array of q values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_array = [1,2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MF_F_n = Fractal.mfdfa(raw.data,n_array,q_array,deg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[\n",
    "    go.Scatter(x=n_array,y=np.log(MF_F_n[:,q]), name='Data fluctuation (q-th order: {})'.format(q_array[q]),mode='markers+lines') for q in range(len(q_array))])\n",
    "fig.update_layout(\n",
    "    height=800, width=800,\n",
    "    xaxis=dict(title='Time (min.)',type='log'),\n",
    "    yaxis=dict(title='log(F(n))')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_h_q = [Fractal.generalized_hurst_exponent(MF_F_n[:,q],n_array) for q in range(len(q_array))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_h_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For q = 2, the result previously obtained with a DFA is recovered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voilà!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
